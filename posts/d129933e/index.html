<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="IDS97Lzd7uweEA7adjgQuo1V__a3xp9oKGq6OuoxZYg">
  <meta name="msvalidate.01" content="81407BB95B6B10326AFF04EEC297B4F2">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"shangxiaaabb.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.17.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="本文通过结合如下论文以及blog：  1、贝叶斯优化研究综述：https:&#x2F;&#x2F;doi.org&#x2F;10.13328&#x2F;j.cnki.jos.005607.2、高斯回归可视化：https:&#x2F;&#x2F;jgoertler.com&#x2F;visual-exploration-gaussian-processes&#x2F;3、贝叶斯优化：http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1012.2599  对贝叶斯优化进行较为全面的介绍，">
<meta property="og:type" content="article">
<meta property="og:title" content="贝叶斯优化">
<meta property="og:url" content="https://shangxiaaabb.github.io/posts/d129933e/index.html">
<meta property="og:site_name" content="Hjie">
<meta property="og:description" content="本文通过结合如下论文以及blog：  1、贝叶斯优化研究综述：https:&#x2F;&#x2F;doi.org&#x2F;10.13328&#x2F;j.cnki.jos.005607.2、高斯回归可视化：https:&#x2F;&#x2F;jgoertler.com&#x2F;visual-exploration-gaussian-processes&#x2F;3、贝叶斯优化：http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1012.2599  对贝叶斯优化进行较为全面的介绍，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/06/10/cFwQxP2Doyfldtn.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/10/RE2hpHuvJ5wWGnB.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-85fb84d30a68bc03e301ed67d868c38b_720w.webp">
<meta property="og:image" content="https://s2.loli.net/2023/06/13/jN7wmdgoxSEu2zb.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/13/EwdIPmZXJ4Uu3QF.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/13/SeJKV91xCI2g4Qj.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/10/k8b4stXOKJfA2Ya.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/13/qRv9E61jIO2hYsn.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/13/tfUN829GmbqKka3.png">
<meta property="og:image" content="https://s2.loli.net/2023/06/10/YTiR82Xsz4SHKxh.png">
<meta property="article:published_time" content="2024-02-24T12:16:55.058Z">
<meta property="article:modified_time" content="2024-02-24T12:16:55.073Z">
<meta property="article:author" content="hjie">
<meta property="article:tag" content="文献笔记">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="优化算法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/06/10/cFwQxP2Doyfldtn.png">


<link rel="canonical" href="https://shangxiaaabb.github.io/posts/d129933e/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://shangxiaaabb.github.io/posts/d129933e/","path":"posts/d129933e/","title":"贝叶斯优化"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>贝叶斯优化 | Hjie</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hjie</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-book"><a href="/books" rel="section"><i class="fa fa-book-open fa-fw"></i>book</a></li><li class="menu-item menu-item-link"><a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96"><span class="nav-number">1.</span> <span class="nav-text">贝叶斯优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8B%E7%BB%8D"><span class="nav-number">1.1.</span> <span class="nav-text">介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%90%86%E6%A8%A1%E5%9E%8B-surrogate-models"><span class="nav-number">1.2.</span> <span class="nav-text">代理模型(surrogate models)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%87%87%E9%9B%86%E5%87%BD%E6%95%B0%EF%BC%88Acquisition-Functions%EF%BC%89"><span class="nav-number">1.3.</span> <span class="nav-text">采集函数（Acquisition Functions）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%E3%80%81probability-of-improvement%EF%BC%88PI%EF%BC%89"><span class="nav-number">1.3.1.</span> <span class="nav-text">1、probability of improvement（PI）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%E3%80%81expected-improvement%EF%BC%88EI%EF%BC%89"><span class="nav-number">1.3.2.</span> <span class="nav-text">2、expected improvement（EI）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%E3%80%81Confidence-bound-criteria%EF%BC%88%E7%BD%AE%E4%BF%A1%E8%BE%B9%E7%95%8C%E7%AD%96%E7%95%A5%EF%BC%89"><span class="nav-number">1.3.3.</span> <span class="nav-text">3、Confidence bound criteria（置信边界策略）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.4.</span> <span class="nav-text">总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1%E3%80%81%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%90%86%E5%87%BD%E6%95%B0"><span class="nav-number">1.4.1.</span> <span class="nav-text">1、常用代理函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%E3%80%81%E5%B8%B8%E7%94%A8%E9%87%87%E9%9B%86%E5%87%BD%E6%95%B0"><span class="nav-number">1.4.2.</span> <span class="nav-text">2、常用采集函数</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81"><span class="nav-number">1.5.</span> <span class="nav-text">代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A8%E8%8D%90"><span class="nav-number">1.6.</span> <span class="nav-text">推荐</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">1.7.</span> <span class="nav-text">参考</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hjie"
      src="/images/head.jpg">
  <p class="site-author-name" itemprop="name">hjie</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/shangxiaaabb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;shangxiaaabb" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hjie20011001@gmail.com" title="E-Mail → mailto:hjie20011001@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shangxiaaabb.github.io/posts/d129933e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.jpg">
      <meta itemprop="name" content="hjie">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hjie">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="贝叶斯优化 | Hjie">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          贝叶斯优化
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-24 20:16:55" itemprop="dateCreated datePublished" datetime="2024-02-24T20:16:55+08:00">2024-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">优化算法</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">论文笔记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>本文通过结合如下论文以及blog：</p>
<blockquote>
<p>1、贝叶斯优化研究综述：<a target="_blank" rel="noopener" href="https://doi.org/10.13328/j.cnki.jos.005607">https://doi.org/10.13328/j.cnki.jos.005607</a>.<br>2、高斯回归可视化：<a target="_blank" rel="noopener" href="https://jgoertler.com/visual-exploration-gaussian-processes/">https://jgoertler.com/visual-exploration-gaussian-processes/</a><br>3、贝叶斯优化：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1012.2599">http://arxiv.org/abs/1012.2599</a></p>
</blockquote>
<p>对贝叶斯优化进行较为全面的介绍，以及部分代码复现</p>
<span id="more"></span>

<h1 id="贝叶斯优化"><a href="#贝叶斯优化" class="headerlink" title="贝叶斯优化"></a>贝叶斯优化</h1><p>[toc]</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>问题一：如果存在函数$y&#x3D;x^2$那么对于这个函数很容易就可以得到他的最小值$x&#x3D;0$时取到最小值，但是如果只告诉我们存在函数$y&#x3D;f(x)$（$f(x)$具体的表达式未知），我们如何找到他的最小值呢？</p>
<p>问题二：对于机器学习、深度学习模型都是由许多参数所决定的（比如说：深度学习中学习率、网络深度等），假如我们通过计算模型的$R^2$来选择我们的参数，那么如何选择参数的值使得$R^2$最大呢？</p>
<p><strong>Grid Search？Random Search？Bayesian optimization？</strong></p>
<blockquote>
<p>超参数优化</p>
<p>百度百科：</p>
<p><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E8%B6%85%E5%8F%82%E6%95%B0/3101858">https://baike.baidu.com/item/%E8%B6%85%E5%8F%82%E6%95%B0/3101858</a></p>
<p>Wiki：</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">https://en.wikipedia.org/wiki/Hyperparameter_optimization</a></p>
</blockquote>
<p>本文主要对<strong>Bayesian optimization</strong>进行解释。<strong>贝叶斯优化</strong>通过有限的步骤进行全局优化。定义我们的待优化函数：</p>
<p>$$<br>x^{*}&#x3D;\underset{x\in X}{argmin}f(x)<br>$$</p>
<blockquote>
<p>上式子中：$x$代表<strong>决策向量</strong>（直观理解为：深度学习中的学习率、网络深度等），$X$代表<strong>决策空间</strong>（直观理解为：以学习率为例，假设我们能从学习率集合$\alpha&#x3D;(0.01,0.02,0.03)$[&lt;–这就是决策空间] 选择最佳学习率[&lt;–这就是我们决策向量]，$f$则代表目标函数（比如上面提到的$R^2$或者机器学习模型$f$））</p>
</blockquote>
<p>许多机器学习中的优化问题都是<strong>黑盒优化</strong>问题，我们函数是一个黑盒函数<a target="_blank" rel="noopener" href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">^1</a>。如何通过<strong>贝叶斯优化</strong>实现**(1)<strong>式子呢？贝叶斯优化的两板斧：（1）surrogate model（</strong>代理模型<strong>）；（2）acquisition function（</strong>采集函数**）。贝叶斯优化框架如下<a target="_blank" rel="noopener" href="https://doi.org/10.13328/j.cnki.jos.005607.">^3</a>：</p>
<img data-src="https://s2.loli.net/2023/06/10/cFwQxP2Doyfldtn.png" alt="202306101452451" style="zoom:80%;"/>

<p>贝叶斯优化框架应用在一维函数$f(x)&#x3D;(x-0.3)^2+0.2sin(20x)$上3次迭代的示例：</p>
<img data-src="https://s2.loli.net/2023/06/10/RE2hpHuvJ5wWGnB.png" alt="图一:贝叶斯优化示例" style="zoom:70%;"/>

<h2 id="代理模型-surrogate-models"><a href="#代理模型-surrogate-models" class="headerlink" title="代理模型(surrogate models)"></a>代理模型(surrogate models)</h2><p>上面提及到机器学习是一个黑盒子(black box)，即我们只知道input和output，所以很难确直接定存在什么样的函数关系<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53826787">^2</a>。既然你的<strong>函数关系</strong>确定不了，那么我们就可以直接找到一个模型对你的函数进行<strong>替代</strong>（代理），这就是贝叶斯优化第一板斧：<strong>代理模型</strong>。（使用概率模型代理原始评估代价高昂的复杂目标函数）</p>
<p>这里主要解释<strong>高斯过程（Gaussian processes，GP）</strong><a target="_blank" rel="noopener" href="https://jgoertler.com/visual-exploration-gaussian-processes/">^4</a></p>
<blockquote>
<p>其他代理模型，感兴趣的可以阅读这篇<a target="_blank" rel="noopener" href="https://doi.org/10.13328/j.cnki.jos.005607">论文</a></p>
<p>WiKi：</p>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B">高斯过程 - 维基百科，自由的百科全书 (wikipedia.org)</a></p>
<p>百度百科：</p>
<p><a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/4535435?structureClickId=4535435&structureId=56eafc20675c3e28256b410f&structureItemId=a46e4d355312e203fffb9c11">高斯过程_百度百科 (baidu.com)</a></p>
<p>高斯过程：<strong>就是一系列关于连续域（时间或空间）的随机变量的联合，而且针对每一个时间或是空间点上的随机变量都是服从高斯分布的</strong></p>
</blockquote>
<hr>
<blockquote>
<p>解释高斯过程前了解<strong>高斯分布</strong>学过概率论的应该都了解，高斯分布其实就是<strong>正态分布</strong>平时所学的大多为一元正态分布，推广到$n$维的高斯分布：</p>
<p>$$<br>X&#x3D;\begin{bmatrix}X_1\X_2\…\X_n\end{bmatrix}∼N(\mu,\sum)<br>$$</p>
<p>其中$\mu$代表均值，$\sum$代表协方差。</p>
</blockquote>
<hr>
<p>高斯过程的数学原理<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1012.2599">^5</a>：</p>
<p>$$<br>f(x)∼GP(m(x),k(x,x^{‘}))<br>$$</p>
<p>其中$m(x)$代表<strong>均值</strong>（为了方便令$m(x)&#x3D;0$），$k$代表<strong>核函数</strong>。常用核函数：</p>
<p>$$<br>k(x_i,x_j)&#x3D;\sum&#x3D;cov(x_i,x_j)&#x3D;exp(-\frac{1}{2}||x_i-x_j||^2)<br>$$</p>
<blockquote>
<p>其他核函数</p>
<img data-src="https://pic4.zhimg.com/80/v2-85fb84d30a68bc03e301ed67d868c38b_720w.webp" alt="202306131551131" style="zoom:90%;"/>
</blockquote>
<p>在高斯过程中，核函数往往就决定了分布的形状，于此同时也就决定我们需要预测函数所具有的特性，对于不同两点$x_i$和$x_j$两点距离近则值接近1反之则接近0。那么可以得到核矩阵为：</p>
<p>$$<br>K&#x3D;\begin{bmatrix}k(x_1,x_1)&amp;…&amp;k(x_1,x_t)\…&amp;…&amp;…\k(x_t,x_1)&amp;…&amp;k(x_1,x_t) \end{bmatrix}<br>$$</p>
<p>以<strong>回归任务</strong>为例<a target="_blank" rel="noopener" href="https://jgoertler.com/visual-exploration-gaussian-processes/">^4</a>，高斯过程定义了潜在函数的<strong>概率分布</strong>，由于这是一个多元高斯分布，这些函数也呈正态分布。通常假设$μ&#x3D; 0$，在没有观察到任何训练数据的情况下。在贝叶斯推断的框架下，将其称之为先验分布 $f(x)∼N(\mu_f,K_f)$。在没观察到任何训练样本，该分布会围绕 $μ_f&#x3D;0$展开（可定义此时先验分布为$f(x)∼N(0,K_f)$）。先验分布的维数和测试点的数目 $N&#x3D;∣X∣$一致。我们将用核函数来建立协方差矩阵，维数为$N×N$。</p>
<img data-src="https://s2.loli.net/2023/06/13/jN7wmdgoxSEu2zb.png" alt="202306131635876" style="zoom:70%;"/>

<blockquote>
<p>以RBF为核函数生成5组样本</p>
</blockquote>
<p>当补充训练样本时得到：</p>
<img data-src="https://s2.loli.net/2023/06/13/EwdIPmZXJ4Uu3QF.png" alt="202306131650854" style="zoom:70%;"/>

<p>输入样本点，数学原理如下：假设观察到样本点为$(x,y)$那么$y$与先验分布$f(x)$的联合高斯分布为：</p>
<p>$$<br>\begin{bmatrix}f(x)\y \end{bmatrix}∼N(\begin{bmatrix}0\0 \end{bmatrix},\begin{bmatrix}K_{ff}&amp;&amp;K_{fy}\K^{T}<em>{fy}&amp;&amp;K</em>{yy} \end{bmatrix})<br>$$</p>
<p>那么此时可以根据联合分布得到$P(y|f)$的分布为：</p>
<p>$$<br>P(y|f)&#x3D;N(\mu(x),\sigma^2(x))<br>$$</p>
<p>其中：$\mu(x)&#x3D;K^{T}<em>{fy}K</em>{ff}^{-1}f(x)$，$\sigma^2(x)&#x3D;K_{yy}-K^{T}<em>{fy}K</em>{ff}^{-1}K_{fy}$</p>
<p>从<strong>回归</strong>的角度对<strong>高斯过程</strong>进行理解：假设我们需要拟合函数为：</p>
<p>$$<br>y&#x3D;sin(2.5x)+sin(x)+0.05x^2+1<br>$$</p>
<p>我们通过设置$x$范围生成输入数据，那么可以得到输出数据$y$那么GP拟合如下：</p>
<img data-src="https://s2.loli.net/2023/06/13/SeJKV91xCI2g4Qj.png" alt="202306131551131" style="zoom:90%;"/>

<p>上图也很容易理解，在$x&lt;10$以前我们输入了数据那么置信区间范围较小，而$x&gt;10$之后由于没有输入数据置信区间范围较大</p>
<blockquote>
<img data-src="https://s2.loli.net/2023/06/10/k8b4stXOKJfA2Ya.png" alt="图一" style="zoom:60%;"/>

<p>具有三个观测值的简单一维高斯过程。实线黑线是给定数据的目标函数的GP代理均值预测，阴影区域表示均值加减方差。</p>
<p>Simple 1D Gaussian process with three observations. The solid black line is the GP surrogate mean prediction of the objective function given the data, and the shaded area shows the mean plus and minus the variance. The superimposed Gaussians correspond to the GP mean and standard deviation ($μ(·) $and $σ(·)) $of prediction at the points, $x_{1:3}$.</p>
</blockquote>
<h2 id="采集函数（Acquisition-Functions）"><a href="#采集函数（Acquisition-Functions）" class="headerlink" title="采集函数（Acquisition Functions）"></a>采集函数（Acquisition Functions）</h2><p>在<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1012.2599">论文</a>中作者对于<strong>采集函数</strong>的描述为：</p>
<p>The role of the acquisition function is to guide the search for the optimum.</p>
<blockquote>
<p>个人理解为：上一节介绍了GP过程中引入新的数据点其联合分布，那么的话我们可以直接引入$n$个点直接将全部$x$进行覆盖，但是这样的话Bayesian optimization就失去其意义了，如何通过最少的点去实现$x^{*}&#x3D;\underset{x\in X}{argmin}f(x)$</p>
</blockquote>
<blockquote>
<p>Acquisition functions are defined such that high acquisition corresponds to potentially high values of the objective function.</p>
<p>采集函数被定义为目标函数的潜在高值</p>
</blockquote>
<p>可以对采集函数理解为：<strong>去找到一个合适的点</strong>。常用的采集函数：</p>
<h3 id="1、probability-of-improvement（PI）"><a href="#1、probability-of-improvement（PI）" class="headerlink" title="1、probability of improvement（PI）"></a>1、probability of improvement（PI）</h3><p>PI去尝试最大化现有的概率$f(x^+)$，其中$x^+&#x3D;\underset{x\in X}{argmax}f(x)$其公式为：</p>
<p>$$<br>PI_{t}(x)&#x3D;P(f_{t}(x) \geq f_{t}(x^+)+\xi)&#x3D;\phi(\frac{\mu_{t}(x)-f_{t}(x^+)-\xi}{\sigma_{t}(x)})<br>$$</p>
<p>其中$\phi(.)$为正则化，$\xi（\xi \geq 0）$为权重。PI策略通过PI提升最大化来选择新一轮的超参组合：</p>
<p>$$<br>x_{t+1}&#x3D;argmax_{x}(PI_{t}(x))<br>$$</p>
<p>其中$x_{t+1}$代表新一轮超参组合。</p>
<h3 id="2、expected-improvement（EI）"><a href="#2、expected-improvement（EI）" class="headerlink" title="2、expected improvement（EI）"></a>2、expected improvement（EI）</h3><p>PI策略选择提升<strong>概率最大</strong>的候选点，这一策略值考虑了提升的概率而没有考虑<strong>提升量</strong>的大小，EI针对此提出：$EI(x)&#x3D;E[max(f_{t+1}(x)-f(x^+),0)]$那么EI函数为：</p>
<p>$$<br>f(n)&#x3D; \begin{cases}<br>(\mu(x)-f(x^+)\phi(Z)+\sigma(x)\phi(Z) &amp; \text {if $\phi(x)&gt;0$} \<br>0 &amp; \text{if $\phi(x)&#x3D;0$ }<br>\end{cases}<br>$$</p>
<p>其中$Z&#x3D;\frac{\mu(x)-f(x^+)}{\sigma(x)}$</p>
<blockquote>
<p>具体公式推导见论文（第13页）：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1012.2599">http://arxiv.org/abs/1012.2599</a></p>
</blockquote>
<h3 id="3、Confidence-bound-criteria（置信边界策略）"><a href="#3、Confidence-bound-criteria（置信边界策略）" class="headerlink" title="3、Confidence bound criteria（置信边界策略）"></a>3、Confidence bound criteria（置信边界策略）</h3><p><strong>1. LCB</strong>(置信下界策略，计算目标函数最小值)</p>
<p>$$<br>LCB(x)&#x3D;\mu(x)-\kappa \phi(x)<br>$$</p>
<p><strong>2. UCB</strong>（置信上界策略，计算目标函数最大值）</p>
<p>$$<br>UCB(x)&#x3D;\mu(x)+\kappa \phi(x)<br>$$</p>
<blockquote>
<p>LCB、UCB中的$\kappa$ is left to the user</p>
</blockquote>
<p><strong>3. GP-UCB</strong></p>
<p>$$<br>GP-UCB&#x3D;\mu(x)+\sqrt{v\tau_{t}}\phi(x)<br>$$</p>
<p>GP-UCB很简单的一种采集策略，以随机变量的置信上界最大化为原则选择下一轮的超参组合</p>
<p><strong>4.其它</strong></p>
<p>见论文：<a target="_blank" rel="noopener" href="https://doi.org/10.13328/j.cnki.jos.005607">https://doi.org/10.13328/j.cnki.jos.005607</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="1、常用代理函数"><a href="#1、常用代理函数" class="headerlink" title="1、常用代理函数"></a>1、常用代理函数</h3><img data-src="https://s2.loli.net/2023/06/13/qRv9E61jIO2hYsn.png" alt="202306132058850" style="zoom:100%;"/>

<h3 id="2、常用采集函数"><a href="#2、常用采集函数" class="headerlink" title="2、常用采集函数"></a>2、常用采集函数</h3><img data-src="https://s2.loli.net/2023/06/13/tfUN829GmbqKka3.png" alt="202306132059038" style="zoom:100%;"/>

<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>代码参考：<a target="_blank" rel="noopener" href="https://github.com/bayesian-optimization/BayesianOptimization">https://github.com/bayesian-optimization/BayesianOptimization</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bayes_opt <span class="keyword">import</span> BayesianOptimization <span class="comment">#调用第三方库</span></span><br><span class="line"><span class="keyword">from</span> skelarn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> r2_score</span><br><span class="line"></span><br><span class="line"><span class="comment">#交叉验证贝叶斯优化</span></span><br><span class="line">X_train, X_test, Y_train, Y_test= train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">100</span>)</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVR</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">svr_cv</span>(<span class="params">C, epsilon, gamma</span>):</span><br><span class="line">    kf = KFold(n_splits=<span class="number">5</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">100</span>)</span><br><span class="line">    svr = SVR(C=C, epsilon=epsilon, gamma=gamma)</span><br><span class="line">    <span class="keyword">for</span> i, (train_index, test_index) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X_train, Y_train.values)):</span><br><span class="line">        svr.fit(X_train[train_index], Y_train.values[train_index])</span><br><span class="line">        pred = svr.predict(X_train[test_index])</span><br><span class="line">        <span class="keyword">return</span> r2_score(pred, Y_train.values[test_index])</span><br><span class="line"></span><br><span class="line">svr_bo = BayesianOptimization(svr_cv,&#123;<span class="string">&#x27;C&#x27;</span>:(<span class="number">1</span>,<span class="number">16</span>), <span class="string">&#x27;epsilon&#x27;</span>:(<span class="number">0</span>,<span class="number">1</span>), <span class="string">&#x27;gamma&#x27;</span>:(<span class="number">0</span>,<span class="number">1</span>)&#125;)</span><br><span class="line"><span class="comment">#输入测试的函数，以及变量的范围</span></span><br><span class="line">svr_bo.maximize()</span><br></pre></td></tr></table></figure>

<img data-src="https://s2.loli.net/2023/06/10/YTiR82Xsz4SHKxh.png" alt="202306101944250" style="zoom:60%;"/>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">svr_bo.<span class="built_in">max</span> <span class="comment">#得到最佳参数</span></span><br><span class="line"><span class="comment">#&#123;&#x27;target&#x27;: 0.9875895309185105,</span></span><br><span class="line"><span class="comment"># &#x27;params&#x27;: &#123;&#x27;C&#x27;: 14.595794386042416,</span></span><br><span class="line"><span class="comment">#  &#x27;epsilon&#x27;: 0.09480102745231553,</span></span><br><span class="line"><span class="comment">#  &#x27;gamma&#x27;: 0.09251046201638335&#125;&#125;</span></span><br></pre></td></tr></table></figure>

<p>通过最佳参数进行测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">svr1 =  SVR(C=<span class="number">14.595794386042416</span>, epsilon=<span class="number">0.09480102745231553</span>, gamma=<span class="number">0.09251046201638335</span>)</span><br><span class="line">svr1.fit(X_train, Y_train)</span><br><span class="line">r2_score(Y_test.values, svr1.predict(X_test))</span><br><span class="line"><span class="comment">#0.9945825852230629</span></span><br></pre></td></tr></table></figure>

<p>高斯拟合代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">n = <span class="number">100</span></span><br><span class="line">x_min = -<span class="number">10</span></span><br><span class="line">x_max = <span class="number">10</span></span><br><span class="line">X = np.sort(np.random.uniform(size=n))*(x_max- x_min) + x_min</span><br><span class="line">X = X.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">eta = np.random.normal(loc=<span class="number">0.0</span>, scale= <span class="number">0.5</span>, size= n)</span><br><span class="line"></span><br><span class="line">y_clean = np.sin(X * <span class="number">2.5</span>) + np.sin(X * <span class="number">1.0</span>)  + np.multiply(X, X) * <span class="number">0.05</span> + <span class="number">1</span></span><br><span class="line">y_clean = y_clean.ravel()</span><br><span class="line">y = y_clean+ eta</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process <span class="keyword">import</span> GaussianProcessRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.gaussian_process.kernels <span class="keyword">import</span> RBF</span><br><span class="line"> </span><br><span class="line">kernel = RBF(</span><br><span class="line">    length_scale=<span class="number">1</span>, </span><br><span class="line">    length_scale_bounds=(<span class="number">1e-2</span>, <span class="number">1e3</span>))</span><br><span class="line"> </span><br><span class="line">gpr = GaussianProcessRegressor( kernel,</span><br><span class="line">                               alpha=<span class="number">0.1</span>,</span><br><span class="line">                               n_restarts_optimizer=<span class="number">5</span>,</span><br><span class="line">                               normalize_y=<span class="literal">True</span>)</span><br><span class="line">gpr.fit(X,y )</span><br><span class="line"><span class="comment">#print(&quot;LML:&quot;, gpr.log_marginal_likelihood())</span></span><br><span class="line"><span class="comment">#print(gpr.get_params())</span></span><br><span class="line">x = np.linspace(x_min - <span class="number">2.0</span>, x_max + <span class="number">7.5</span>, n * <span class="number">2</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y_pred, y_pred_std = gpr.predict(x, return_std=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">8</span>))</span><br><span class="line">plt.plot(x, y_pred,linewidth = <span class="number">3</span>, label=<span class="string">&quot;GP mean&quot;</span>)</span><br><span class="line">plt.plot(X, y_clean, linewidth = <span class="number">3</span>,  label=<span class="string">&quot;Original y&quot;</span>)</span><br><span class="line">plt.plot(X, y,linewidth = <span class="number">3</span>, label=<span class="string">&quot;Noisy y&quot;</span>)</span><br><span class="line">plt.scatter(X, np.zeros_like(X), marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.fill_between(x.ravel(),</span><br><span class="line">                 y_pred - y_pred_std,</span><br><span class="line">                 y_pred + y_pred_std,</span><br><span class="line">                label=<span class="string">&quot;95% confidence interval&quot;</span>,</span><br><span class="line">                interpolate=<span class="literal">True</span>,</span><br><span class="line">                facecolor=<span class="string">&#x27;blue&#x27;</span>,</span><br><span class="line">                alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim(<span class="number">5</span>, <span class="number">15</span>)</span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>

<h2 id="推荐"><a href="#推荐" class="headerlink" title="推荐"></a>推荐</h2><p>1、Gaussian Processes for Machine Learning：<a target="_blank" rel="noopener" href="https://gaussianprocess.org/gpml/chapters/RW.pdf">https://gaussianprocess.org/gpml/chapters/RW.pdf</a></p>
<p>2、贝叶斯优化论文：<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1012.2599">http://arxiv.org/abs/1012.2599</a></p>
<p>3、贝叶斯优化博客：<a target="_blank" rel="noopener" href="https://banxian-w.com/article/2023/3/27/2539.html">https://banxian-w.com/article/2023/3/27/2539.html</a></p>
<p>4、可视化高斯过程：<a target="_blank" rel="noopener" href="https://jgoertler.com/visual-exploration-gaussian-processes/#MargCond">https://jgoertler.com/visual-exploration-gaussian-processes/#MargCond</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>1、<a target="_blank" rel="noopener" href="http://krasserm.github.io/2018/03/21/bayesian-optimization/">http://krasserm.github.io/2018/03/21/bayesian-optimization/</a></p>
<p>2、<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53826787">https://zhuanlan.zhihu.com/p/53826787</a></p>
<p>3、崔佳旭, 杨博. 贝叶斯优化方法和应用综述[J&#x2F;OL]. 软件学报, 2018, 29(10): 3068-3090. <a target="_blank" rel="noopener" href="https://doi.org/10.13328/j.cnki.jos.005607">https://doi.org/10.13328/j.cnki.jos.005607</a>.</p>
<p>4、<a target="_blank" rel="noopener" href="https://jgoertler.com/visual-exploration-gaussian-processes/">https://jgoertler.com/visual-exploration-gaussian-processes/</a></p>
<p>5、<a target="_blank" rel="noopener" href="http://arxiv.org/abs/1012.2599">http://arxiv.org/abs/1012.2599</a></p>
<p>6、<a target="_blank" rel="noopener" href="https://www.cvmart.net/community/detail/3502">https://www.cvmart.net/community/detail/3502</a></p>
<p>7、<a target="_blank" rel="noopener" href="https://gaussianprocess.org/gpml/chapters/RW.pdf">https://gaussianprocess.org/gpml/chapters/RW.pdf</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%96%87%E7%8C%AE%E7%AC%94%E8%AE%B0/" rel="tag"># 文献笔记</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/" rel="tag"># 优化算法</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/ab615615/" rel="prev" title="GAN阅读笔记">
                  <i class="fa fa-chevron-left"></i> GAN阅读笔记
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hjie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/code-unfold.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.11/pdfobject.min.js","integrity":"sha256-N6JtCNwaYm6kizuG92UtOOXamRHPwu+V1yF10g3bu/c="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","cdn":"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
