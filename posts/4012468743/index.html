<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="IDS97Lzd7uweEA7adjgQuo1V__a3xp9oKGq6OuoxZYg">
  <meta name="msvalidate.01" content="81407BB95B6B10326AFF04EEC297B4F2">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"shangxiaaabb.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.17.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测，从数据产生决策树的机器学习技术叫做 决策树学习">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树算法">
<meta property="og:url" content="https://shangxiaaabb.github.io/posts/4012468743/index.html">
<meta property="og:site_name" content="Hjie">
<meta property="og:description" content="决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测，从数据产生决策树的机器学习技术叫做 决策树学习">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2023/06/04/YiKdrHCL4758yJI.png">
<meta property="article:published_time" content="2024-02-24T12:16:50.444Z">
<meta property="article:modified_time" content="2024-02-24T12:16:50.475Z">
<meta property="article:author" content="hjie">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="评价标准">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/06/04/YiKdrHCL4758yJI.png">


<link rel="canonical" href="https://shangxiaaabb.github.io/posts/4012468743/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://shangxiaaabb.github.io/posts/4012468743/","path":"posts/4012468743/","title":"决策树算法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>决策树算法 | Hjie</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hjie</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-book"><a href="/books" rel="section"><i class="fa fa-book-open fa-fw"></i>book</a></li><li class="menu-item menu-item-link"><a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>友链</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">一、什么是决策树算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E5%88%92%E5%88%86%E6%A0%87%E5%87%86"><span class="nav-number">2.</span> <span class="nav-text">二、划分标准</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A-ID3%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%88%92%E5%88%86%E6%A0%87%E5%87%86"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 信息增益(ID3决策树算法划分标准)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0-CART%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E5%88%92%E5%88%86%E6%A0%87%E5%87%86"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 基尼指数(CART决策树算法划分标准)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E8%AF%84%E4%BB%B7"><span class="nav-number">3.</span> <span class="nav-text">三、评价</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E4%BB%A3%E7%A0%81"><span class="nav-number">4.</span> <span class="nav-text">四、代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B"><span class="nav-number">5.</span> <span class="nav-text">五、决策树算法流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">6.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hjie"
      src="/images/head.jpg">
  <p class="site-author-name" itemprop="name">hjie</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">27</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/shangxiaaabb" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;shangxiaaabb" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hjie20011001@gmail.com" title="E-Mail → mailto:hjie20011001@gmail.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://shangxiaaabb.github.io/posts/4012468743/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/head.jpg">
      <meta itemprop="name" content="hjie">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hjie">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="决策树算法 | Hjie">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          决策树算法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-02-24 20:16:50" itemprop="dateCreated datePublished" datetime="2024-02-24T20:16:50+08:00">2024-02-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><strong>决策树</strong>是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测，从数据产生决策树的机器学习技术叫做 <strong>决策树学习</strong> ,通俗说就是<strong>决策树</strong></p>
<span id="more"></span>

<h2 id="一、什么是决策树算法"><a href="#一、什么是决策树算法" class="headerlink" title="一、什么是决策树算法"></a>一、什么是决策树算法</h2><p><strong>决策树</strong>是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测，从数据产生决策树的机器学习技术叫做 <strong>决策树学习</strong> ,通俗说就是<strong>决策树</strong></p>
<blockquote>
<p>维基百科：<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E5%86%B3%E7%AD%96%E6%A0%91#%E7%AE%80%E4%BB%8B">https://zh.wikipedia.org/zh-cn/%E5%86%B3%E7%AD%96%E6%A0%91#%E7%AE%80%E4%BB%8B</a></p>
</blockquote>
<p>不懂？那我们引用<strong>周志华老师西瓜书</strong>上的例子，立马就能有一个大概了解。</p>
<blockquote>
<p>比如你带你表妹现在要去西瓜摊买西瓜，而作为卖西瓜老手的你总是能够一眼挑选出那个最好吃最甜的西瓜，而表妹总是选的不尽人意，表妹突发奇想向你请教怎么选出一个心满意足的西瓜。你说：得价钱！不对不对咱们在谈买西瓜，你说咱们啊，先看“它是什么颜色?”，如果是“青绿色”，则我们再看 “它的根蒂是什么形态?”，如果是“蜷缩 ”，我们再判断“它敲起来是什么声音?”，最后，我们得出最终决策：这个瓜很润，呸呸呸，是很甜！</p>
</blockquote>
<p>我相信你现在应该有一个大概了解了，不就是选择一个目的（我们需要进行的分类的标签），然后根据一系列的特征从而满足我们的目的，以后我们就借用这个特征去挑选“好瓜”。但是！先泼一盆凉水给你，我们怎么开始第一步呢？这还不简单，直接选择”颜色“呀！但是我们为什么不从”根茎“下手呢？下面就是我们要将的如何进行划分，也就是划分标准。</p>
<h2 id="二、划分标准"><a href="#二、划分标准" class="headerlink" title="二、划分标准"></a>二、划分标准</h2><h3 id="2-1-信息增益-ID3决策树算法划分标准"><a href="#2-1-信息增益-ID3决策树算法划分标准" class="headerlink" title="2.1 信息增益(ID3决策树算法划分标准)"></a>2.1 信息增益(ID3决策树算法划分标准)</h3><p>必须先了解信息熵这个概念，<strong>信息熵</strong>，维基百科上的定义：是接收的每条消息中包含的信息的平均量。这里，“消息”代表来自分布或数据流中的事件、样本或特征。（熵最好理解为不确定性的量度而不是确定性的量度，因为越随机的信源的熵越大）来自信源的另一个特征是样本的概率分布。这里的想法是，比较不可能发生的事情，当它发生了，会提供更多的信息。由于一些其他的原因，把信息（熵）定义为概率分布的对数的相反数是有道理的。事件的概率分布和每个事件的信息量构成了一个随机变量，这个随机变量的均值（即期望）就是这个分布产生的信息量的平均值（即熵）。熵的概念最早起源于物理学，用于度量一个热力学系统的无序程度。在信息论里面，熵是对不确定性的测量。但是在信息世界，<strong>熵越高，则能传输越多的信息，熵越低，则意味着传输的信息越少</strong>。还是不懂？那你不妨记住：<strong>信息熵是对信息量的一种衡量</strong></p>
<blockquote>
<p>维基百科：<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-cn/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)">https://zh.wikipedia.org/zh-cn/%E7%86%B5_(%E4%BF%A1%E6%81%AF%E8%AE%BA)</a><br>Shannon,C.E.(1948).A Mathematical Theory of Communication. Bell System Technical Journal,27(3),379–423.doi:10.1002&#x2F;j.1538-7305.1948.tb01338.x</p>
</blockquote>
<p>一般地，划分数据集的大原则是：<strong>将无序的数据变得更加有序</strong>。在划分数据集之前之后信息发生的变化称为信息增益，知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，<strong>获得信息增益最高的特征就是最好的选择</strong>。也就是说我们可用信息增益来进行决策树的划分属性选择，他们公式如下：</p>
<p>$$<br>信息熵：Ent(D)&#x3D;-\displaystyle\sum_{k&#x3D;1}^{|y|}p_klog_2p_k \取负数：保证信息熵&gt;0<br>$$</p>
<p>其中$Ent(D)$的值越小，则消息熵越小</p>
<p>$$<br>信息增益Gain(D,a)&#x3D;Ent(D)-\sum_{v&#x3D;1}^{V}\frac{|D^v|}{|D|}Ent(D^v) \V:离散属性a的可能取值的个数<br>$$</p>
<p>怎么使用？再次借用周志华老师书上例子，我们来区分好瓜坏瓜。</p>
<blockquote>
<img data-src="https://s2.loli.net/2023/06/04/YiKdrHCL4758yJI.png" alt="202306041908136" style="zoom:75%;"/>

<ul>
<li><strong>注释</strong>：本文都是采用的ID3决策树算法</li>
</ul>
<p>因为我们的目的是区分好瓜坏瓜所以先计算其信息熵：</p>
<p>$$<br>Ent(D)&#x3D;-\sum_{k&#x3D;1}^{2}p_klog_2p_k&#x3D;-(\frac{8}{17}log_2(\frac{8}{17})+\frac{9}{17}log_2(\frac{9}{17}))&#x3D;0.998<br>$$</p>
<p>同理可得假设我们以色泽进行分类，那么色泽有三种可能 {青绿、乌黑、浅白}，我们再计算每种色泽下所对应好坏瓜的概率（$p_1:好，p_2:坏$）：青绿：$p_1&#x3D;0.5,p_2&#x3D;0.5$；乌黑：$p_1&#x3D;\frac{4}{6}，p_2&#x3D;\frac{2}{6}$；浅白：$p_1&#x3D;\frac{1}{5},p_2&#x3D;\frac{4}{5}$；这样一来我们可以计算各种信息增益：</p>
<p>$$<br>Ent(青绿)&#x3D;1，Ent(乌黑)&#x3D;0.918，Ent(浅白)&#x3D;0.722<br>$$</p>
<p>然后计算信息增益:</p>
<p>$$<br>Gain(D,色泽)&#x3D;Ent(D)-\sum_{v&#x3D;1}^{V}\frac{|D^v|}{|D|}Ent(D^v)&#x3D;0.998-(\frac{6}{17}\times1+\frac{6}{17}\times0.918+\frac{5}{17}\times0.722)&#x3D;0.109<br>$$</p>
<p>$$<br>同理可得其他的信息增益：\Gain(D,根蒂)&#x3D;0.143;\Gain(D,敲声)&#x3D;0.141;\Gain(D,纹理)&#x3D;0.381;\Gain(D,脐部)&#x3D;0.289;\Gain(D,触感)&#x3D;0.006;<br>$$</p>
<p>纹理的信息增益最大，所以我们取纹理作为我们的划分标准，同理从纹理出发再取计算其他属性，并且得到信息增益，以此类推只到所有标准都划分完毕。</p>
</blockquote>
<h3 id="2-2-基尼指数-CART决策树算法划分标准"><a href="#2-2-基尼指数-CART决策树算法划分标准" class="headerlink" title="2.2 基尼指数(CART决策树算法划分标准)"></a>2.2 基尼指数(CART决策树算法划分标准)</h3><h2 id="三、评价"><a href="#三、评价" class="headerlink" title="三、评价"></a>三、评价</h2><p><strong>决策树的优点</strong><br>1、决策树易于理解和实现.人们在通过解释后都有能力去理解决策树所表达的意义<br>2、对于决策树，数据的准备往往是简单或者是不必要的.其他的技术往往要求先把数据一般化，比如去掉多余的或者空白的属性<br>3、能够同时处理数据型和常规型属性。其他的技术往往要求数据属性的单一<br>4、是一个白盒模型如果给定一个观察的模型，那么根据所产生的决策树很容易推出相应的逻辑表达式<br>5、易于通过静态测试来对模型进行评测。表示有可能测量该模型的可信度<br>6、在相对短的时间内能够对大型数据源做出可行且效果良好的结果<br><strong>决策树的缺点</strong><br>对于那些各类别样本数量不一致的数据，在决策树当中信息增益的结果偏向于那些具有更多数值的特征</p>
<p>文章如若有错误，欢迎大佬们批评指正。💪💪</p>
<h2 id="四、代码"><a href="#四、代码" class="headerlink" title="四、代码"></a>四、代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算信息熵</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ent</span>(<span class="params">data</span>):</span><br><span class="line">    data_length = <span class="built_in">len</span>(data)</span><br><span class="line">    dic = &#123;&#125;</span><br><span class="line">    <span class="comment">#统计个数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        data_leable = i[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> data_leable <span class="keyword">not</span> <span class="keyword">in</span> dic:</span><br><span class="line">            dic[data_leable] = <span class="number">0</span></span><br><span class="line">        dic[data_leable] +=<span class="number">1</span></span><br><span class="line">   <span class="comment">#return dic</span></span><br><span class="line">    <span class="comment">#计算信息熵</span></span><br><span class="line">    ent_number = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> dic:</span><br><span class="line">        num1 = <span class="built_in">float</span>(dic[j])/data_length</span><br><span class="line">        ent_number = ent_number - num1*log(num1,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> ent_number</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#划分数据集合</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_split</span>(<span class="params">data, axis, value</span>):</span><br><span class="line">    data_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> i[axis] == value:</span><br><span class="line">            feat = i[:axis]</span><br><span class="line">            feat.extend(i[axis+<span class="number">1</span>:])</span><br><span class="line">            data_list.append(feat)</span><br><span class="line">    <span class="keyword">return</span> data_list</span><br><span class="line"></span><br><span class="line"><span class="comment">#extend与append函数区别：a.extend(b):将b的值全部加到a中；a.append(b):将b列表加到a中</span></span><br><span class="line"><span class="comment"># a = [1,2]</span></span><br><span class="line"><span class="comment"># b = [3,4]</span></span><br><span class="line"><span class="comment"># c = [3,4]</span></span><br><span class="line"><span class="comment"># a.append(b)</span></span><br><span class="line"><span class="comment"># c.extend(b)</span></span><br><span class="line"><span class="comment"># print(a,c)</span></span><br><span class="line"><span class="comment"># [1, 2, [3, 4]] [3, 4, 3, 4]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算信增益,并且挑选最佳特征</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gain_chose</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    data_ent:信息熵</span></span><br><span class="line"><span class="string">    feat_list:每一种标签的全部数据</span></span><br><span class="line"><span class="string">    feat_value:每一种标签下的取值</span></span><br><span class="line"><span class="string">    data_gain:信息增益</span></span><br><span class="line"><span class="string">    ent_number:计算各自列下的信息熵</span></span><br><span class="line"><span class="string">    prop:计算概率</span></span><br><span class="line"><span class="string">    best_feature:最佳划分特征</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data_base_length = <span class="built_in">len</span>(data[<span class="number">0</span>])-<span class="number">1</span></span><br><span class="line">    ent_base = ent(data)</span><br><span class="line">    gain_max = -<span class="number">1</span> <span class="comment">#取任何小于0的值都可以</span></span><br><span class="line">    <span class="comment">#第一个for循环得到每一列，第二个for循环则是对每一列中取值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(data_base_length):</span><br><span class="line">        feat_list = [a[i] <span class="keyword">for</span> a <span class="keyword">in</span> data]</span><br><span class="line">        feat_value = <span class="built_in">set</span>(feat_list)</span><br><span class="line">        ent_number = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> feat_value:</span><br><span class="line">            data_split_use = data_split(data, i, j)</span><br><span class="line">            prop = <span class="built_in">len</span>(data_split_use)/<span class="built_in">float</span>(<span class="built_in">len</span>(data_split_use))</span><br><span class="line">            ent_number = ent_number + prop * ent(data_split_use)</span><br><span class="line">        data_gain = ent_base - ent_number </span><br><span class="line">        <span class="keyword">if</span> data_gain &gt; gain_max:</span><br><span class="line">            gain_max = data_gain</span><br><span class="line">            best_feature = i</span><br><span class="line">    <span class="keyword">return</span> best_feature</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘制决策树</span></span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">majorityCnt</span>(<span class="params">classList</span>):</span><br><span class="line">    classCount=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys(): classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet,labels</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    classList:存储dataset中的标签</span></span><br><span class="line"><span class="string">    bestFeatLabel:根节点</span></span><br><span class="line"><span class="string">    myTree:存储树结构</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    classList = [example[-<span class="number">1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="comment"># 如果全是一个特征，直接返回</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == <span class="built_in">len</span>(classList): </span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 如果数组长度为1，则</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) == <span class="number">1</span>: </span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line"></span><br><span class="line">    bestFeat = gain_chose(dataSet)</span><br><span class="line">    bestFeatLabel = labels[bestFeat]     <span class="comment"># 挑选出根节点</span></span><br><span class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat]) <span class="comment"># 删除以免再次选到</span></span><br><span class="line"></span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniqueVals = <span class="built_in">set</span>(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[:] </span><br><span class="line">        myTree[bestFeatLabel][value] = createTree(data_split(dataSet, bestFeat, value),subLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree   </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="五、决策树算法流程"><a href="#五、决策树算法流程" class="headerlink" title="五、决策树算法流程"></a>五、决策树算法流程</h2><p>第一步：计算信息熵：利用<strong>哈希表</strong>得到分类标签的对应数量关系，而后感觉对应的数量关系计算信息熵。<br>第二步：计算信息增益并且挑选出最佳特征：分为两个步骤。第一步：划分数据集合，第二步计算</p>
<ul>
<li>第一步：以西瓜例子说明，我们在挑选好 ‘yes’or’no’ 之后，我们要回过头观察前面特征的集合（色泽：a），而后在色泽：a中分别计算满足’yes’or’no’的信息熵。依次类推分别得到纹理等特征的信息熵。</li>
<li>第二步：在我们前一步所得到的信息熵中计算信息增益</li>
<li>第三步：挑选信息增益最大的值<br>第三步：挑选好最佳特征之后开始绘制决策树</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote>
<p>周志华 《西瓜书》</p>
<p>《机器学习实战》</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86/" rel="tag"># 评价标准</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/undefined/" rel="prev" title="Hello World">
                  <i class="fa fa-chevron-left"></i> Hello World
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/2592384004/" rel="next" title="机器学习评价标准">
                  机器学习评价标准 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hjie</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js" integrity="sha256-2Pmvv0kuTBOenSvLm6bvfBSSHrUJ+3A7x6P5Ebd07/g=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/code-unfold.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.11/pdfobject.min.js","integrity":"sha256-N6JtCNwaYm6kizuG92UtOOXamRHPwu+V1yF10g3bu/c="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","cdn":"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
